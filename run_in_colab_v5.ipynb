{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ğŸš€ è’¼ç‹¼ AI v2.2 - ä¸€éµå•Ÿå‹•å™¨</h1>\n",
    "\n",
    "æ­¡è¿ä½¿ç”¨ï¼é»æ“Šä¸‹æ–¹å„²å­˜æ ¼å·¦å´çš„ â–¶ï¸ **åŸ·è¡ŒæŒ‰éˆ•**ä¾†å•Ÿå‹•æ‚¨çš„ AI åˆ†æå¹³å°ã€‚\n",
    "\n",
    "**å•Ÿå‹•æµç¨‹ï¼š**\n",
    "1. **ç’°å¢ƒè¨­å®š**ï¼šè‡ªå‹•ä¸‹è¼‰å°ˆæ¡ˆç¨‹å¼ç¢¼ä¸¦å®‰è£æ‰€æœ‰å¿…è¦çš„ Python å’Œ Node.js å¥—ä»¶ã€‚\n",
    "2. **å•Ÿå‹•æœå‹™**ï¼šåŒæ™‚å•Ÿå‹•å¾Œç«¯ FastAPI å’Œå‰ç«¯ Next.js æœå‹™ã€‚\n",
    "3. **å»ºç«‹é€šé“**ï¼šä½¿ç”¨ `ngrok` å»ºç«‹ä¸€å€‹å®‰å…¨çš„å…¬é–‹ç¶²å€ï¼Œä»¥ä¾¿æ‚¨å­˜å–æœå‹™ã€‚\n",
    "4. **åµŒå…¥ä»‹é¢**ï¼š**æ‚¨çš„æ‡‰ç”¨ç¨‹å¼ä½¿ç”¨è€…ä»‹é¢å°‡æœƒç›´æ¥é¡¯ç¤ºåœ¨æ­¤å„²å­˜æ ¼çš„ä¸‹æ–¹**ï¼Œç„¡éœ€é›¢é–‹ Colabã€‚\n",
    "\n",
    "---\n",
    "**æç¤º**ï¼šé¦–æ¬¡åŸ·è¡Œå¯èƒ½éœ€è¦å¹¾åˆ†é˜æ™‚é–“ä¾†ä¸‹è¼‰å’Œå®‰è£å¥—ä»¶ï¼Œè«‹è€å¿ƒç­‰å€™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a1b2c3d4-e5f6-7890-a1b2-c3d4e5f67890"
   },
   "outputs": [],
   "source": [
    "#@title â–¶ï¸ é»æ­¤ä¸€éµå•Ÿå‹• Wolf AI å¹³å°\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "from pyngrok import ngrok\n",
    "from IPython.display import display, IFrame, HTML\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# --- è¨­å®š --- \n",
    "REPO_URL = \"https://github.com/hsp1234-web/wolfai_v2_jules.git\"\n",
    "REPO_PATH = \"/content/wolfai_v2_jules\"\n",
    "NGROK_AUTH_TOKEN = \"\" # å»ºè­°å¡«å¯«æ‚¨çš„ ngrok Authtoken ä»¥ç²å¾—æ›´ç©©å®šé€£ç·š\n",
    "\n",
    "def stream_output(process, log_file):\n",
    "    \"\"\"å°‡å­é€²ç¨‹çš„è¼¸å‡ºå³æ™‚å¯«å…¥æ—¥èªŒæª”æ¡ˆ\"\"\"\n",
    "    with open(log_file, 'w') as f:\n",
    "        for line in iter(process.stdout.readline, ''):\n",
    "            f.write(line)\n",
    "            f.flush()\n",
    "\n",
    "print(\"â³ [1/5] é–‹å§‹æº–å‚™ç’°å¢ƒ...\")\n",
    "\n",
    "if os.path.exists(REPO_PATH):\n",
    "    print(f\"   -> å€‰åº«ç›®éŒ„ {REPO_PATH} å·²å­˜åœ¨ï¼Œæ­£åœ¨æ›´æ–°...\")\n",
    "    subprocess.run(f'cd {REPO_PATH} && git pull', shell=True, check=True)\n",
    "else:\n",
    "    print(f\"   -> æ­£åœ¨å¾ {REPO_URL} ä¸‹è¼‰å°ˆæ¡ˆ...\")\n",
    "    subprocess.run(f'git clone {REPO_URL} {REPO_PATH}', shell=True, check=True)\n",
    "\n",
    "print(\"âœ… [2/5] å°ˆæ¡ˆç¨‹å¼ç¢¼å·²å‚™å¦¥ï¼\")\n",
    "print(\"â³ [3/5] æ­£åœ¨å®‰è£å¾Œç«¯èˆ‡å‰ç«¯ä¾è³´å¥—ä»¶ (æ­¤æ­¥é©Ÿå¯èƒ½éœ€è¦æ•¸åˆ†é˜)...\")\n",
    "\n",
    "# å®‰è£æ‰€æœ‰ä¾è³´\n",
    "subprocess.run(f'pip install -q -r {REPO_PATH}/backend/requirements.txt', shell=True, check=True)\n",
    "subprocess.run(f'npm install --prefix {REPO_PATH}/frontend', shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) # éš±è— npm çš„å¤§é‡è¼¸å‡º\n",
    "\n",
    "print(\"âœ… [4/5] æ‰€æœ‰ä¾è³´å·²å®‰è£ï¼\")\n",
    "print(\"â³ [5/5] æ­£åœ¨å•Ÿå‹•å¾Œç«¯èˆ‡å‰ç«¯æœå‹™...\")\n",
    "\n",
    "# å•Ÿå‹•å¾Œç«¯\n",
    "backend_process = subprocess.Popen(['uvicorn', 'main:app', '--host', '0.0.0.0', '--port', '8000'], cwd=f'{REPO_PATH}/backend', stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "threading.Thread(target=stream_output, args=(backend_process, 'backend.log')).start()\n",
    "print(\"   -> å¾Œç«¯ FastAPI æœå‹™å·²åœ¨èƒŒæ™¯å•Ÿå‹•ã€‚\")\n",
    "\n",
    "print(\"   -> Checking backend health (/api/v1/health)...\")\n",
    "start_time = time.time()\n",
    "backend_healthy = False\n",
    "while time.time() - start_time < 60:\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:8000/api/v1/health\")\n",
    "        if response.status_code == 200:\n",
    "            print(\"   -> Backend is healthy!\")\n",
    "            backend_healthy = True\n",
    "            break\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        # Backend not up yet\n",
    "        pass\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"   -> An error occurred during health check: {e}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "if not backend_healthy:\n",
    "    print(\"   -> ERROR: Backend health check timed out after 60 seconds.\")\n",
    "    # Log backend output for debugging\n",
    "    print(\"   -> Displaying backend logs for diagnostics...\")\n",
    "    with open('backend.log', 'r') as f:\n",
    "        backend_logs = f.read()\n",
    "        if backend_logs:\n",
    "            print(\"--- Backend Log ---\")\n",
    "            print(backend_logs)\n",
    "            print(\"--- End Backend Log ---\")\n",
    "        else:\n",
    "            print(\"   -> Backend log is empty.\")\n",
    "    raise RuntimeError(\"Backend service failed to start or become healthy within 60 seconds.\")\n",
    "\n",
    "# å•Ÿå‹•å‰ç«¯\n",
    "frontend_process = subprocess.Popen(['npm', 'run', 'dev'], cwd=f'{REPO_PATH}/frontend', stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "threading.Thread(target=stream_output, args=(frontend_process, 'frontend.log')).start()\n",
    "print(\"   -> å‰ç«¯ Next.js æœå‹™å·²åœ¨èƒŒæ™¯å•Ÿå‹•ã€‚\")\n",
    "\n",
    "print(\"   -> Waiting for frontend service to become ready (checking frontend.log)...\")\n",
    "start_time = time.time()\n",
    "frontend_ready = False\n",
    "ready_messages = [\"event - compiled client and server successfully\", \"Ready\", \"started server on 0.0.0.0:3000\"]\n",
    "while time.time() - start_time < 120:\n",
    "    try:\n",
    "        with open('frontend.log', 'r') as f:\n",
    "            log_content = f.read()\n",
    "            if any(msg in log_content for msg in ready_messages):\n",
    "                print(\"   -> Frontend service is ready!\")\n",
    "                frontend_ready = True\n",
    "                break\n",
    "    except FileNotFoundError:\n",
    "        # Log file might not be created yet\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"   -> An error occurred while checking frontend log: {e}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "if not frontend_ready:\n",
    "    print(\"   -> ERROR: Frontend readiness check timed out after 120 seconds.\")\n",
    "    print(\"   -> Displaying frontend logs for diagnostics...\")\n",
    "    try:\n",
    "        with open('frontend.log', 'r') as f:\n",
    "            frontend_logs = f.read()\n",
    "            if frontend_logs:\n",
    "                print(\"--- Frontend Log ---\")\n",
    "                print(frontend_logs)\n",
    "                print(\"--- End Frontend Log ---\")\n",
    "            else:\n",
    "                print(\"   -> Frontend log is empty or could not be read.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"   -> Frontend log file (frontend.log) not found.\")\n",
    "    raise RuntimeError(\"Frontend service failed to become ready within 120 seconds.\")\n",
    "\n",
    "# è¨­å®š ngrok\n",
    "if NGROK_AUTH_TOKEN:\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "print(\"   -> All services ready. Establishing ngrok tunnel...\") # New print statement\n",
    "\n",
    "# å»ºç«‹ ngrok é€šé“ä¸¦é¡¯ç¤º\n",
    "try:\n",
    "    public_url = ngrok.connect(3000).public_url # Assuming frontend runs on port 3000\n",
    "    print(f\"\nğŸ‰ğŸ‰ğŸ‰ æ‚¨çš„ AI å¹³å°å·²ä¸Šç·šï¼ ğŸ‰ğŸ‰ğŸ‰\")\n",
    "    print(f\"ğŸŒ å…¬é–‹ç¶²å€: {public_url}\")\n",
    "    display(HTML(\"<h2>â†“ æ‚¨å¯ä»¥ç›´æ¥åœ¨ä¸‹æ–¹æ“ä½œ WolfAI ä»‹é¢ â†“</h2>\"))\n",
    "    display(IFrame(public_url, width='100%', height=800))\n",
    "except Exception as e:\n",
    "    print(f\"\nğŸ›‘ éŒ¯èª¤ï¼šç„¡æ³•å»ºç«‹ ngrok é€šé“ã€‚è«‹æª¢æŸ¥æ‚¨çš„ Authtoken æˆ– Colab ç¶²è·¯ç‹€æ…‹ã€‚éŒ¯èª¤è¨Šæ¯: {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
